{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makes some test on the Laplacian, Biharmonic and Heisenberg layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second derivatives of the chi matrix are used to evaluate the expected number of photons in each channels\n",
    "The fourth derivatives are used to determin the uncertainties in the photon number\n",
    "\n",
    "Here we test the uncertainty layer on different states\n",
    "\n",
    "<img src=\"../img/logo_circular.png\" width=\"20\" height=\"20\" />@by claudio<br>\n",
    "\n",
    "nonlinearxwaves@gmail.com<br>\n",
    "@created 24 december 2020<br>\n",
    "@version 23 sep 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # disable warning messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from thqml import phasespace as ps\n",
    "from thqml.utilities import utilities\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_real=tf.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension (number of modes times 2, N=2n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vacuum by the Gaussian state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacuum = ps.VacuumLayer(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a vacuum layer with modified covariance matrix g to test derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [0. 2. 0. 0.]\n",
      " [0. 0. 3. 0.]\n",
      " [0. 0. 0. 4.]]\n"
     ]
    }
   ],
   "source": [
    "g=np.eye(N); \n",
    "for i in range(N):\n",
    "    g[i,i]=i+1\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModifiedVacuum=ps.GaussianLayer(g, np.zeros((N,1)), trainable=False, dtype=tf_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'gaussian_layer_1/g:0' shape=(4, 4) dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0.],\n",
       "       [0., 2., 0., 0.],\n",
       "       [0., 0., 3., 0.],\n",
       "       [0., 0., 0., 4.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModifiedVacuum.g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squeezed mode on mode 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra=0.1;\n",
    "phia=np.pi/2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezer=ps.SingleModeSqueezerLayer(N, r_np=ra, theta_np=phia, n_squeezed=0, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coherent state (Displacer on mode 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_np = 3.14\n",
    "lambda_np = np.pi/2\n",
    "#theta =0\n",
    "dinput=np.zeros((N,1));\n",
    "#dinput[2]=np.sqrt(2)*A_np*np.cos(lambda_np);\n",
    "#dinput[3]=np.sqrt(2)*A_np*np.sin(lambda_np);\n",
    "displacer=ps.DisplacementLayerConstant(dinput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy training points (not used for training in this example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nbatch=10\n",
    "gtarget=np.eye(N)\n",
    "dtarget=2.4*np.ones((N,1))\n",
    "xtrain = np.random.rand(Nbatch, N)-0.5\n",
    "ytrain =np.zeros_like(xtrain)\n",
    "dtrain = np.zeros((Nbatch,N))\n",
    "gtrain = np.zeros((Nbatch,N,N))\n",
    "for j in range(Nbatch):\n",
    "    for i in range(N):\n",
    "        dtrain[j,i]=dtarget[i]\n",
    "        for k in range(N):\n",
    "            gtrain[j,i,k]=gtarget[i,k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for the vacuum state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xin = tf.keras.layers.Input(N)\n",
    "chir, chii = ModifiedVacuum(xin)\n",
    "modelVacuum = tf.keras.Model(inputs = xin, outputs=[chir, chii])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Details the operation to evaluate the Laplacian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Laplacian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(np.zeros((1,N)), dtype=tf_real)\n",
    "with tf.GradientTape() as t1:\n",
    "    with tf.GradientTape() as t2:\n",
    "        cr, _ = modelVacuum(x)\n",
    "    cr_x = t2.gradient(cr,x)\n",
    "cr_xy = t1.jacobian(cr_x,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here cr has shape [1,1], cr_x has shape [1,N], and cr_xy has shape [1,N,1,N,1,N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "(1, 4)\n",
      "(1, 4, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "print(cr.shape); print(cr_x.shape);print(cr_xy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor([[0. 0. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[[-0.5  0.   0.   0. ]]\n",
      "\n",
      "  [[ 0.  -1.   0.   0. ]]\n",
      "\n",
      "  [[ 0.   0.  -1.5  0. ]]\n",
      "\n",
      "  [[ 0.   0.   0.  -2. ]]]], shape=(1, 4, 1, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(cr); print(cr_x);print(cr_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a list of indices to extract the diagonal part of the Hessian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0], [0, 1, 0, 1], [0, 2, 0, 2], [0, 3, 0, 3]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1_np=[]\n",
    "for i in range(N):\n",
    "    list1_np.append([0,i]*2)\n",
    "print(list1_np)\n",
    "list1=tf.constant(list1_np)\n",
    "list1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather the diagonal elements by the list of indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.5 -1.  -1.5 -2. ]], shape=(1, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "cr_xx=tf.reshape(tf.gather_nd(cr_xy, tf.constant(list1)),[1,N]);  # the cast of list1 to tensor is not strictly needed\n",
    "# the reshape for cr_xx is needed to have a shape compatible with matrix multiplication\n",
    "print(cr_xx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return the laplacian by combinining the derivatives with Rp and Rq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.5 -1.5]], shape=(1, 2), dtype=float32) tf.Tensor([[-1. -2.]], shape=(1, 2), dtype=float32) tf.Tensor([[-1.5 -3.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "Rq_np, Rp_np, _ = ps.RQRP(N)\n",
    "RQ=tf.constant(Rq_np)\n",
    "RP=tf.constant(Rp_np)\n",
    "dqq = tf.matmul(cr_xx, RQ)\n",
    "dpp = tf.matmul(cr_xx, RP)\n",
    "lapla=dqq+dpp\n",
    "print(dqq, dpp, lapla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with the LaplacianLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-1.5 -3.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "lapla_test=ps.LaplacianLayer(N)(chir, chii, modelVacuum);  # create a laplacian layer\n",
    "modelVacuumLapla = tf.keras.Model(inputs = xin, outputs=lapla_test) # add the layer to a model\n",
    "print(modelVacuumLapla(xtrain)) # evaluate the model\n",
    "# the output is the same as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Details the operation to evaluate the Biharmonic (squared laplacian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7f31eceded40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7f31eceded40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(np.zeros((1,N)),dtype=tf_real)\n",
    "with tf.GradientTape() as t4:\n",
    "    with tf.GradientTape() as t3:\n",
    "        with tf.GradientTape() as t2:\n",
    "            with tf.GradientTape() as t1:\n",
    "                cr, _ = modelVacuum(x)\n",
    "            cr_x = t1.gradient(cr, x)\n",
    "        cr_xy = t2.jacobian(cr_x, x)\n",
    "    cr_xyz = t3.jacobian(cr_xy, x)\n",
    "cr_xyzw = t4.jacobian(cr_xyz, x)\n",
    "#print(cr);print(cr_x);print(cr_xy);print(cr_xyz);print(cr_xyzw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the indices to extract diagonal part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 0 0 0]\n",
      " [0 1 0 1]\n",
      " [0 2 0 2]\n",
      " [0 3 0 3]], shape=(4, 4), dtype=int32) tf.Tensor(\n",
      "[[0 0 0 0]\n",
      " [1 1 1 1]\n",
      " [2 2 2 2]\n",
      " [3 3 3 3]], shape=(4, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# indeces to diagonal the biharmonic and laplacian\n",
    "list_2x =[]\n",
    "list_4x =[]\n",
    "for i in range(N):\n",
    "    list_2x.append([0,i]*2);\n",
    "    list_4x.append([i]*4);\n",
    "    #list_4x.append([0,i]*4);\n",
    "# list_2x is [[0,0,0,0],[0,1,0,1],[0,2,0,2],[0,3,0,3]] for N=4\n",
    "# list_4x is [[0,0,0,0],[1,1,1,1],[2,2,2,2],[3,3,3,3] for N=4            \n",
    "indices_2x=tf.constant(list_2x) \n",
    "indices_4x=tf.constant(list_4x)\n",
    "print(indices_2x, indices_4x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the diagonal parts of laplacian and biharmonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.5 -1.  -1.5 -2. ]], shape=(1, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# extract the diagonal part by gather\n",
    "cr_2x=tf.reshape(tf.gather_nd(cr_xy,indices_2x), [1, N])\n",
    "print(cr_2x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 0.75  3.    6.75 12.  ]], shape=(1, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "cr_xyzw=tf.reshape(cr_xyzw,[N,N,N,N])\n",
    "cr_4x=tf.gather_nd(cr_xyzw,indices_4x)\n",
    "cr_4x=tf.reshape(cr_4x,[1,N])\n",
    "print(cr_4x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the diagonal part to have laplacian and biharmonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-1.5 -3.5]], shape=(1, 2), dtype=float32) tf.Tensor([[ 4.75 24.75]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dqq = tf.matmul(cr_2x,RQ)\n",
    "dpp = tf.matmul(cr_2x,RP)\n",
    "dqqqq = tf.matmul(cr_4x,RQ)\n",
    "dpppp = tf.matmul(cr_4x,RP)\n",
    "biharmonic = dqqqq+dpppp+2*tf.multiply(dqq,dpp)\n",
    "laplacian = dqq+dpp\n",
    "print(laplacian, biharmonic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with the Biharmonic layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 4.75, 24.75]], dtype=float32)>, <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-1.5, -3.5]], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "biharm_test=ps.BiharmonicLayer(N)(chir, chii, modelVacuum);  # create a laplacian layer\n",
    "modelVacuumBiharm = tf.keras.Model(inputs = xin, outputs=biharm_test) # add the layer to a model\n",
    "print(modelVacuumBiharm(xtrain)) # evaluate the model\n",
    "# the output is the same as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Heisenberg Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a model with a vacuum mode and a coherent mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4\n",
    "vacuum = ps.VacuumLayer(N) \n",
    "# this is the true vacuum, not the wrong one used above to test\n",
    "# displacement vector for the coherent mode\n",
    "dinput = np.zeros((N,1));\n",
    "nc0 = 4 # number of photons in the coherent mode\n",
    "dinput[2]=np.sqrt(nc0) \n",
    "dinput[3]=np.sqrt(nc0)\n",
    "# Glauber Layer\n",
    "D=ps.DisplacementLayerConstant(dinput)\n",
    "# Heisenber Layer\n",
    "H=ps.HeisenbergLayer(N)\n",
    "# Build the model\n",
    "xin = tf.keras.Input((N,))\n",
    "x0, a0  = D(xin)\n",
    "chir, chii = vacuum(x0,a0)\n",
    "model = tf.keras.Model(inputs = xin, outputs=[chir, chii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the Heisenberg layer\n",
    "nboson, nboson2, Dn2 = H(chir, chii, model)\n",
    "# create modified model including the Heisenber Layer\n",
    "modelHeisenberg = tf.keras.Model(inputs = xin, outputs=[nboson, nboson2, Dn2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the HeisenberLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0., 4.]], dtype=float32)>, <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 0., 20.]], dtype=float32)>, <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0., 4.]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(modelHeisenberg(xtrain)); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark, the model is computationally intensive as it use the Jacobian layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected we have 0 photons in the vacuum state, <br>\n",
    "nc0 photons in the coherent state (4 for nc0=4) <br>\n",
    "0 is the expected value for second moment of photons of the vacuum <br>\n",
    "nc0+nc0^2 is second moment of photons in the coherent state (20 for nc0=4) <br>\n",
    "0 is the uncertainty of photons in the vaccum <br>\n",
    "nc0 is also the uncertainty of photons in the coherent state (4 for nc0=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use special Heisenberg for Gaussian states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "HG = ps.HeisenbergGaussianLayer(N)\n",
    "# add the Heisenberg Gaussian layer\n",
    "nboson, nboson2, Dn2 = HG(chir, chii, model)\n",
    "# create modified model including the Heisenber Layer\n",
    "modelHeisenbergG = tf.keras.Model(inputs = xin, outputs=[nboson, nboson2, Dn2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0., 4.]], dtype=float32)>, <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 0., 20.]], dtype=float32)>, <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0., 4.]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(modelHeisenbergG(xtrain)); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the biharmonic layer with Gaussian states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 4.75, 24.75]], dtype=float32)>, <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-1.5, -3.5]], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "biharm_test=ps.BiharmonicGaussianLayer(N)(chir, chii, modelVacuum);  # create a laplacian layer\n",
    "modelVacuumBiharmG = tf.keras.Model(inputs = xin, outputs=biharm_test) # add the layer to a model\n",
    "print(modelVacuumBiharmG(xtrain)) # evaluate the model\n",
    "# the output is the same as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtained same results as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
