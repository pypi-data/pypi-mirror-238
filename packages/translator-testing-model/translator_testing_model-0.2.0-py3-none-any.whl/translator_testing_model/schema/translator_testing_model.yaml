---
id: https://w3id.org/TranslatorSRI/TranslatorTestingModel
name: Translator-Testing-Model
title: Translator Testing Data Model
version: 0.0.0
description: |-
  Data model to formalize the structure of test assets, cases, suites and related metadata
  applied to run the diverse polymorphic testing objectives for the Biomedical Data Translator system.
license: MIT
see_also:
  - https://TranslatorSRI.github.io/TranslatorTestingModel

prefixes:
  ttm: https://w3id.org/TranslatorSRI/TranslatorTestingModel/
  linkml: https://w3id.org/linkml/
  biolink: https://w3id.org/biolink/
  schema: http://schema.org/
  example: https://example.org/

default_prefix: ttm
default_range: string

imports:
  - linkml:types

classes:

  TestEntity:
    description: >-
      Abstract global 'identification' class shared as a parent with
      all major model classes within the data model for Translator testing.
    abstract: true
    tree_root: true
    slots:
      - id
      - name
      - description
      - tags

  TestMetadata:
    description: >-
      Represents metadata related to (external SME, SMURF, Translator feedback, 
      large scale batch, etc.) like the provenance of test assets, cases and/or suites.
    is_a: TestEntity
    slots:
      - test_source
      - test_reference
      - test_objective

  TestAsset:
    description: >-
      Represents a Test Asset, which is a single specific instance of
      TestCase-agnostic semantic parameters representing the
      specification of a Translator test target with inputs and (expected) outputs.
    is_a: TestEntity
    slots:
      - input_id
      - input_name
      - predicate
      - output_id
      - output_name
      - expected_output
      - test_issue
      - semantic_severity
      - in_v1
      - well_known
      - runner_settings
    slot_usage:
      id:
        aliases: ["AssetIdentifier"]
        range: uriorcurie
      tags:
        description: >-
          One or more 'tags' slot values (inherited from TestEntity) should generally
          be defined to specify TestAsset membership in a "Block List" collection
      runner_settings:
        description: >-
          Settings for the test harness, e.g. "inferred"

  AcceptanceTestAsset:
    is_a: TestAsset
    description: >-
      Model derived from Jenn's test asset design and Shervin's runner JSON here as an example.
    slots:
      - must_pass_date
      - must_pass_environment
      - scientific_question
      - string_entry
      - direction
      - answer_informal_concept
      - expected_result
#      - curie  # use input_id
      - top_level
      - query_node
      - notes

#  QueryAnswerPair:
#    description: >-
#      Represents a QueryAnswerPair specification type of Test Asset.
#      (is this class really needed? Let's assume that the nothing
#      is added above the other test types)
#    # aliases: [""]
#    is_a: TestAsset
  
  TestEdgeData:
    description: >-
      Represents a single Biolink Model compliant instance of a
      subject-predicate-object edge that can be used for testing.
    is_a: TestAsset

  TestCase:
    description: >-
      Represents a single enumerated instance of Test Case, derived from a 
      given collection of one or more TestAsset instances (the value of the
      'test_assets' slot) which define the 'inputs' and 'outputs' of the
      TestCase, used to probe a particular test condition.
    is_a: TestEntity
    slots:
      - test_env
      - test_case_type
      - query_type
      - test_assets
      - preconditions
    slot_usage:
      test_case_type:
        description: >-
          Is this valid or even necessary with the class names already
          available from classes of 'test_assets' used (seems redundant?)
      test_assets:
        aliases: ["Block List"]
        description: >-
          One or more 'tags' slot values (inherited from TestEntity)
          should generally be defined as filters to specify TestAsset
          membership in 'test_assets' slot ("Block List") collection.
      tags:
        description: >-
          One or more 'tags' slot values (inherited from TestEntity) should generally
          be defined as filters to specify TestAsset membership in a "Block List" collection.

  TestCaseSpecification:
    description: >-
      Parameterized declaration of the Test Case generator which dynamically
      generates a collection of Test Cases from Test Assets, using applicable heuristics.
    is_a: TestEntity

  AcceptanceTestCase:
    is_a: TestCase
    description: >-
      See AcceptanceTestAsset above for more details.
    slot_usage:
      test_assets:
        range: AcceptanceTestAsset

  QuantitativeTestCase:
    is_a: TestCase
    description: >-
      Assumed additional model from Shervin's runner JSON here as an example.  This schema is not yet complete.
    slot_usage:
#      test_assets:
#        range: QuantitativeTestAsset

  ComplianceTestCase:
    is_a: TestCase
    description: >-
      TRAPI and Biolink Model standards compliance test
    slot_usage:
#      test_assets:
#        range: ComplianceTestAsset

  KnowledgeGraphNavigationTestCase:
    is_a: TestCase
    description: >-
      Knowledge Graph navigation integration test
    slot_usage:
#      test_assets:
#        range: KnowledgeGraphNavigationTestAsset

  OneHopTestCase:
    is_a: KnowledgeGraphNavigationTestCase
    description: >-
      'One Hop' Knowledge Graph navigation integration test
    slot_usage:
#      test_assets:
#        range: OneHopTestAsset

  TestSuite:
    is_a: TestEntity
    description: >-
      Specification of a set of Test Cases, one of either with a
      static list of 'test_cases' or a dynamic 'test_case_specification' slot values.
      Note: at least one slot or the other, but generally not both(?) needs to be present.
    slots:
      - test_metadata
      - test_persona
      - test_cases
      - test_case_specification

  AcceptanceTestSuite:
    is_a: TestSuite
    description:

  BenchmarkTestSuite:
    description:
     is_a: TestSuite
     
  StandardsComplianceTestSuite:
    description: >-
      Test suite for testing Translator components against releases of standards like TRAPI and the Biolink Model.
    is_a: TestSuite

  OneHopTestSuite:
    description: >-
      Test case for testing the integrity of "One Hop" knowledge graph retrievals sensa legacy SRI_Testing harness.
    is_a: TestSuite

  Precondition:
    description: >-
      Represents a precondition for a TestCase
    is_a: TestEntity
    slots:

slots:

  runner_settings:
    description: >-
      Settings for the test harness
    range: string
    multivalued: true
    required: true

  id:
    identifier: true
    slot_uri: schema:identifier
    range: uriorcurie
    description: A unique identifier for a Test Entity

  name:
    slot_uri: schema:name
    description: A human-readable name for a Test Entity

  description:
    slot_uri: schema:description
    description: A human-readable description for a Test Entity

  tags:
    slot_uri: schema:additionalType
    description: >-
      A human-readable tags for categorical memberships of a TestEntity (preferably a URI or CURIE).
      Typically used to aggregate instances of TestEntity into formally typed or ad hoc lists.
    multivalued: true

  test_source:
    description: Provenance of a specific set of test assets, cases and/or suites.
    range: TestSourceEnum

  test_reference:
    aliases: ["GitHubIssue"]
    description: >-
      Source documentation where original test particulars are registered (e.g. Github repo)
    range: uriorcurie

  test_objective:
    description: >-
      Testing objective behind specified set of test particulars
      (e.g. acceptance pass/fail; benchmark; quantitative)
    range: TestObjectiveEnum

  input_id:
    aliases: ["InputID, node normalized"]
    range: uriorcurie

  input_name:
    aliases: ["InputName (user choice)"]

  predicate:
    aliases: ["Query"]

  output_id:
    aliases: ["OutputID"]
    range: uriorcurie

  output_name:
    aliases: ["OutputName"]

  expected_output:
    aliases: ["Expected Output"]
    range: ExpectedOutputEnum

  test_issue:
    aliases: ["issue label"]
    range: TestIssueEnum

  semantic_severity:
    aliases: ["Semantic Severity"]
    range: SemanticSeverityEnum

  in_v1:
    aliases: ["In v1"]
    range: boolean

  well_known:
    aliases: ["Well Known"]
    range: boolean

  test_metadata:
    description: >-
      Test metadata describes the external provenance, cross-references and objectives for a given test.
    range: TestMetadata

  test_persona:
    description: >-
      A Test persona describes the user or operational context of a given test.
    range: TestPersonaEnum

  test_assets:
    description: >-
      List of explicitly enumerated Test Assets. The class attributes of
      TestAsset would be included in the TestCase versus being referred to by
      the identifier (curie) of the TestAsset. That is, this would be a list of
      objects (in JSONSchema serialization) versus a list of strings (where
      each string is an identifier pointing to another class).
    range: TestAsset
    multivalued: true
    inlined: true
    inlined_as_list: true
    required: true

  test_cases:
    description: >-
      List of explicitly enumerated Test Cases.
    range: TestCase
    multivalued: true
    inlined: true
    required: false

  test_case_specification:
    description: >-
      Declarative specification of a set of Test Cases generated elsewhere (i.e. within a Test Runner)
    range: TestCaseSpecification
    required: false

  must_pass_date:
    description: >-
      The date by which this test must pass
    range: date
    examples:
      - value: "2023-09-01"

  must_pass_environment:
    description: >-
      The deployment environment within which this test must pass.
    range: TestEnvEnum
    examples:
      - value: "prod"
      - value: "ci"
      - value: "test"

  scientific_question:
    description: >-
      The full human-readable scientific question a SME would ask,
      which is encoded into the test asset.
    range: string
    examples:
      - value: "What drugs may treat multiple sclerosis?"
      - value: "What gene is upregulated?"

  string_entry:
    aliases: ["trapi node 2", "disease"]
    description: >-
      The object of the core triple to be tested
    range: string
    examples:
      - value: "multiple sclerosis"
      - value: "Castlemans"

  direction:
    description: >-
      The direction of the expected query result triple
    range: DirectionEnum

  answer_informal_concept:
    description: >-
      An answer that is returned from the test case, note: this must be combined with the expected_result
      to form a complete answer.  It might make sense to couple these in their own object instead of
      strictly sticking to the flat schema introduced by the spreadsheet here:
      https://docs.google.com/spreadsheets/d/1yj7zIchFeVl1OHqL_kE_pqvzNLmGml_FLbHDs-8Yvig/edit#gid=0
    range: string
    examples:
      - value: "fingolimod"
      - value: "natalizumab"
      - value: "lead"
      - value: "great answer here"

  expected_result:
    description: >-
      The expected result of the query
    range: ExpectedResultsEnum

#  curie:
#    description: >-
#      The curie of the query; this is only used in AcceptanceTestCase
#      which is now converted to an AcceptanceTestAsset which has 'input_id'
#    range: curie

  top_level:
    description: >-
      The answer must return in these many results
    range: integer

  query_node:
    description: >-
      The node of the (templated) TRAPI query to replace
    range: NodeEnum

  notes:
    description: >-
      The notes of the query
    range: string

  requires_trapi:
    description: >-
      Does this test require a TRAPI-compliant query to run?
    range: boolean

  test_env:
    description: >-
      Deployment environment within which the associated TestSuite is run.
    range: TestEnvEnum

  test_case_type:
    description: >-
      Type of TestCase.
    range: TestCaseTypeEnum

  query_type:
    description: >-
      Type of TestCase query.
    range: QueryTypeEnum

  preconditions:
    range: Precondition
    multivalued: true

enums:

  TestSourceEnum:
    permissible_values:
      SME:
        description: (External) Subject Matter Expert
      SMURF:
        description: Subject Matter User Reasonably Familiar, generally Translator-internal biomedical science expert
      GitHubUserFeedback:
        description: Git hub hosted issue from which a test asset/case/suite may be derived.
      TACT:
        is_a: GitHubUserFeedback
        description: Technical Advisory Committee, generally posting semantic use cases as Translator Feedback issues
      BenchMark:
        description: Curated benchmark tests
      TranslatorTeam:
        description: Translator funded KP or ARA team generating test assets/cases/suites for their resources.
      TestDataLocation:
        description: Current SRI_Testing-like test data edges specific to KP or ARA components

  TestObjectiveEnum:
    permissible_values:
      AcceptanceTest:
        description: Acceptance (pass/fail) test
      BenchmarkTest:
        description: Semantic benchmarking
      QuantitativeTest:
        description: Quantitative test

  TestPersonaEnum:
    permissible_values:
      All:
      Clinical:
        description: >-
          An MD or someone working in the clinical field.
      LookUp:
        description: >-
          Looking for an answer for a specific patient.
      Mechanistic:
        description: >-
          Someone working on basic biology questions or drug discoveries
          where the study of the biological mechanism.

  QueryTypeEnum:
    description: >-
      Query
    permissible_values:
      treats:
        aliases: "treats(creative)"
        description:

  ExpectedOutputEnum:
    description: >-
      Expected output values for instances of Test Asset or Test Cases(?).
      (Note: does this Enum overlap with 'ExpectedResultsEnum' below?)
    permissible_values:
      Top_Answer:
        description:
      Acceptable:
        description:
      BadButForgivable:
        description:
      NeverShow:
        description:
      number_1_TopAnswer:
        is_a: Top_Answer
        description:
      number_2_Acceptable:
        is_a: Acceptable
        description:
      number_3_BadButForgivable:
        is_a: BadButForgivable
        description:
      number_4_NeverShow:
        is_a: NeverShow
        description:

  ExpectedResultsEnum:
    description: >-
      Does this Enum overlap with 'ExpectedOutputEnum' above?
    permissible_values:
      include_good:
        description: >-
          The query should return the result in this test case
      exclude_bad:
        description: >-
          The query should not return the result in this test case

  NodeEnum:
    description: >-
      Target node of a Subject-Predicate-Object driven query
    permissible_values:
      subject:
      object:

  TestEnvEnum:
    description: >-
      Testing environments within which a TestSuite is
      run by a TestRunner scheduled by the TestHarness.
    permissible_values:
      dev:
        description: Development
      ci:
        description: Continuous Integration
      test:
        description: Test
      prod:
        description: Production

  TestCaseTypeEnum:
    description: >-
      Enumerated tags for types of test (generally applied to a TestCase).
    permissible_values:
      acceptance:
        description: Acceptance test
      quantitative:
        description: Quantitative test
      compliance:
        description: Standards compliance test
      kg_navigation:
        description: Knowledge Graph navigation integration test
      one_hop:
        is_a: kg_navigation
        description: One Hop navigation test

  TestIssueEnum:
    permissible_values:
      causes not treats:
        description:
      TMKP:
        description: >-
          'Text Mining Knowledge Provider' generated relationship?
      category too generic:
        description:
      contraindications:
        description:
      chemical roles:
        description:
      test_issue:
        description:

  SemanticSeverityEnum:
    description: From Jenn's worksheet, empty or ill defined (needs elaboration)
    permissible_values:
      High:
        description:
      Low:
        description:
      NotApplicable:
        description:

  DirectionEnum:
    permissible_values:
      increased:
      decreased:
