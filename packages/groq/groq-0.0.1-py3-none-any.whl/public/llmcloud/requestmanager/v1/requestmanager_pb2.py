# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: public/llmcloud/requestmanager/v1/requestmanager.proto
"""Generated protocol buffer code."""
import os
import sys
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()

from buf.validate import validate_pb2 as buf_dot_validate_dot_validate__pb2
from google.api import annotations_pb2 as google_dot_api_dot_annotations__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n6public/llmcloud/requestmanager/v1/requestmanager.proto\x12!public.llmcloud.requestmanager.v1\x1a\x1b\x62uf/validate/validate.proto\x1a\x1cgoogle/api/annotations.proto\"\xd9\x01\n\x1fGetTextCompletionStreamResponse\x12\"\n\nrequest_id\x18\x01 \x01(\tH\x00R\trequestId\x88\x01\x01\x12\x1d\n\x07\x63ontent\x18\x02 \x01(\tH\x01R\x07\x63ontent\x88\x01\x01\x12N\n\x05stats\x18\x03 \x01(\x0b\x32\x33.public.llmcloud.requestmanager.v1.PerformanceStatsH\x02R\x05stats\x88\x01\x01\x42\r\n\x0b_request_idB\n\n\x08_contentB\x08\n\x06_stats\"\x9d\x06\n\x18GetTextCompletionRequest\x12!\n\x08model_id\x18\x01 \x01(\tB\x06\xbaH\x03\xc8\x01\x01R\x07modelId\x12+\n\rsystem_prompt\x18\x02 \x01(\tB\x06\xbaH\x03\xc8\x01\x01R\x0csystemPrompt\x12\x64\n\x07history\x18\x03 \x03(\x0b\x32J.public.llmcloud.requestmanager.v1.GetTextCompletionRequest.HistoryMessageR\x07history\x12\'\n\x0buser_prompt\x18\x04 \x01(\tB\x06\xbaH\x03\xc8\x01\x01R\nuserPrompt\x12\x17\n\x04seed\x18\x05 \x01(\rH\x00R\x04seed\x88\x01\x01\x12,\n\nmax_tokens\x18\x06 \x01(\rB\x08\xbaH\x05*\x03\x10\x84@H\x01R\tmaxTokens\x88\x01\x01\x12\x36\n\x0btemperature\x18\x07 \x01(\x02\x42\x0f\xbaH\x0c\n\n\x1d\x00\x00\x00@%\x00\x00\x00\x00H\x02R\x0btemperature\x88\x01\x01\x12)\n\x05top_p\x18\x08 \x01(\x02\x42\x0f\xbaH\x0c\n\n\x1d\x00\x00\x80?-\x00\x00\x00\x00H\x03R\x04topP\x88\x01\x01\x12%\n\x05top_k\x18\t \x01(\rB\x0b\xbaH\x08*\x06\x18\x80\xfa\x01(\x00H\x04R\x04topK\x88\x01\x01\x1a`\n\x0eHistoryMessage\x12\x1f\n\x0buser_prompt\x18\x01 \x01(\tR\nuserPrompt\x12-\n\x12\x61ssistant_response\x18\x02 \x01(\tR\x11\x61ssistantResponse:\xb2\x01\xbaH\xae\x01\x1a\xab\x01\n(get_text_completion_request.query_length\x12\x44user_prompt length plus system_prompt length must be less than 65536\x1a\x39size(this.user_prompt) + size(this.system_prompt) < 65536B\x07\n\x05_seedB\r\n\x0b_max_tokensB\x0e\n\x0c_temperatureB\x08\n\x06_top_pB\x08\n\x06_top_k\"\x9f\x01\n\x19GetTextCompletionResponse\x12\x1d\n\nrequest_id\x18\x01 \x01(\tR\trequestId\x12\x18\n\x07\x63ontent\x18\x02 \x01(\tR\x07\x63ontent\x12I\n\x05stats\x18\x03 \x01(\x0b\x32\x33.public.llmcloud.requestmanager.v1.PerformanceStatsR\x05stats\"\xb6\x01\n\x10PerformanceStats\x12%\n\x0etime_generated\x18\x01 \x01(\x01R\rtimeGenerated\x12)\n\x10tokens_generated\x18\x02 \x01(\rR\x0ftokensGenerated\x12%\n\x0etime_processed\x18\x03 \x01(\x01R\rtimeProcessed\x12)\n\x10tokens_processed\x18\x04 \x01(\rR\x0ftokensProcessed2\xac\x03\n\x15RequestManagerService\x12\xcc\x01\n\x17GetTextCompletionStream\x12;.public.llmcloud.requestmanager.v1.GetTextCompletionRequest\x1a\x42.public.llmcloud.requestmanager.v1.GetTextCompletionStreamResponse\".\x82\xd3\xe4\x93\x02(\"#/v1/request_manager/text_completion:\x01*0\x01\x12\xc3\x01\n\x11GetTextCompletion\x12;.public.llmcloud.requestmanager.v1.GetTextCompletionRequest\x1a<.public.llmcloud.requestmanager.v1.GetTextCompletionResponse\"3\x82\xd3\xe4\x93\x02-\"(/v1/request_manager/text_completion_full:\x01*B\xb4\x02\n%com.public.llmcloud.requestmanager.v1B\x13RequestmanagerProtoP\x01ZMgit.groq.io/cloud/go-proto/public/llmcloud/requestmanager/v1;requestmanagerv1\xa2\x02\x03PLR\xaa\x02!Public.Llmcloud.Requestmanager.V1\xca\x02\"Public_\\Llmcloud\\Requestmanager\\V1\xe2\x02.Public_\\Llmcloud\\Requestmanager\\V1\\GPBMetadata\xea\x02$Public::Llmcloud::Requestmanager::V1b\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'public.llmcloud.requestmanager.v1.requestmanager_pb2', _globals)
if _descriptor._USE_C_DESCRIPTORS == False:
  _globals['DESCRIPTOR']._options = None
  _globals['DESCRIPTOR']._serialized_options = b'\n%com.public.llmcloud.requestmanager.v1B\023RequestmanagerProtoP\001ZMgit.groq.io/cloud/go-proto/public/llmcloud/requestmanager/v1;requestmanagerv1\242\002\003PLR\252\002!Public.Llmcloud.Requestmanager.V1\312\002\"Public_\\Llmcloud\\Requestmanager\\V1\342\002.Public_\\Llmcloud\\Requestmanager\\V1\\GPBMetadata\352\002$Public::Llmcloud::Requestmanager::V1'
  _globals['_GETTEXTCOMPLETIONREQUEST'].fields_by_name['model_id']._options = None
  _globals['_GETTEXTCOMPLETIONREQUEST'].fields_by_name['model_id']._serialized_options = b'\272H\003\310\001\001'
  _globals['_GETTEXTCOMPLETIONREQUEST'].fields_by_name['system_prompt']._options = None
  _globals['_GETTEXTCOMPLETIONREQUEST'].fields_by_name['system_prompt']._serialized_options = b'\272H\003\310\001\001'
  _globals['_GETTEXTCOMPLETIONREQUEST'].fields_by_name['user_prompt']._options = None
  _globals['_GETTEXTCOMPLETIONREQUEST'].fields_by_name['user_prompt']._serialized_options = b'\272H\003\310\001\001'
  _globals['_GETTEXTCOMPLETIONREQUEST'].fields_by_name['max_tokens']._options = None
  _globals['_GETTEXTCOMPLETIONREQUEST'].fields_by_name['max_tokens']._serialized_options = b'\272H\005*\003\020\204@'
  _globals['_GETTEXTCOMPLETIONREQUEST'].fields_by_name['temperature']._options = None
  _globals['_GETTEXTCOMPLETIONREQUEST'].fields_by_name['temperature']._serialized_options = b'\272H\014\n\n\035\000\000\000@%\000\000\000\000'
  _globals['_GETTEXTCOMPLETIONREQUEST'].fields_by_name['top_p']._options = None
  _globals['_GETTEXTCOMPLETIONREQUEST'].fields_by_name['top_p']._serialized_options = b'\272H\014\n\n\035\000\000\200?-\000\000\000\000'
  _globals['_GETTEXTCOMPLETIONREQUEST'].fields_by_name['top_k']._options = None
  _globals['_GETTEXTCOMPLETIONREQUEST'].fields_by_name['top_k']._serialized_options = b'\272H\010*\006\030\200\372\001(\000'
  _globals['_GETTEXTCOMPLETIONREQUEST']._options = None
  _globals['_GETTEXTCOMPLETIONREQUEST']._serialized_options = b'\272H\256\001\032\253\001\n(get_text_completion_request.query_length\022Duser_prompt length plus system_prompt length must be less than 65536\0329size(this.user_prompt) + size(this.system_prompt) < 65536'
  _globals['_REQUESTMANAGERSERVICE'].methods_by_name['GetTextCompletionStream']._options = None
  _globals['_REQUESTMANAGERSERVICE'].methods_by_name['GetTextCompletionStream']._serialized_options = b'\202\323\344\223\002(\"#/v1/request_manager/text_completion:\001*'
  _globals['_REQUESTMANAGERSERVICE'].methods_by_name['GetTextCompletion']._options = None
  _globals['_REQUESTMANAGERSERVICE'].methods_by_name['GetTextCompletion']._serialized_options = b'\202\323\344\223\002-\"(/v1/request_manager/text_completion_full:\001*'
  _globals['_GETTEXTCOMPLETIONSTREAMRESPONSE']._serialized_start=153
  _globals['_GETTEXTCOMPLETIONSTREAMRESPONSE']._serialized_end=370
  _globals['_GETTEXTCOMPLETIONREQUEST']._serialized_start=373
  _globals['_GETTEXTCOMPLETIONREQUEST']._serialized_end=1170
  _globals['_GETTEXTCOMPLETIONREQUEST_HISTORYMESSAGE']._serialized_start=833
  _globals['_GETTEXTCOMPLETIONREQUEST_HISTORYMESSAGE']._serialized_end=929
  _globals['_GETTEXTCOMPLETIONRESPONSE']._serialized_start=1173
  _globals['_GETTEXTCOMPLETIONRESPONSE']._serialized_end=1332
  _globals['_PERFORMANCESTATS']._serialized_start=1335
  _globals['_PERFORMANCESTATS']._serialized_end=1517
  _globals['_REQUESTMANAGERSERVICE']._serialized_start=1520
  _globals['_REQUESTMANAGERSERVICE']._serialized_end=1948
# @@protoc_insertion_point(module_scope)
