{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 3668\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 408\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1725\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name_or_path = \"gpt2\"\n",
    "task = \"mrpc\"\n",
    "\n",
    "padding_max_len = 128\n",
    "if any(k in model_name_or_path for k in (\"gpt\", \"opt\", \"bloom\")):\n",
    "    padding_side = \"left\"\n",
    "else:\n",
    "    padding_side = \"right\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    # padding_side=padding_side,  # TODO: left or right?\n",
    "    max_length=padding_max_len,\n",
    ")\n",
    "if getattr(tokenizer, \"pad_token_id\") is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "datasets = load_dataset(\"glue\", task)\n",
    "# print(datasets)\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # max_length=None => use the model max length (it's actually the default)\n",
    "    outputs = tokenizer(\n",
    "        examples[\"sentence1\"],\n",
    "        examples[\"sentence2\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",  # TODO: Must pad to same length?\n",
    "        max_length=padding_max_len,\n",
    "    )\n",
    "    return outputs\n",
    "\n",
    "\n",
    "tokenized_datasets = datasets.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"idx\", \"sentence1\", \"sentence2\"],\n",
    ")\n",
    "\n",
    "# We also rename the 'label' column to 'labels' which is the expected name for labels by the models of the\n",
    "# transformers library\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "\n",
    "\n",
    "# TODO: Use Trainer interface.\n",
    "def train(model, tokenized_train, tokenized_eval):\n",
    "    device = \"cuda\"\n",
    "    num_epochs = 1\n",
    "    lr = 3e-4\n",
    "    batch_size = 32\n",
    "\n",
    "    optimizer = AdamW(params=model.parameters(), lr=lr)\n",
    "    metric = evaluate.load(\"glue\", task)\n",
    "\n",
    "    # # Instantiate scheduler\n",
    "    # lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    #     optimizer=optimizer,\n",
    "    #     num_warmup_steps=0.06 * (len(train_dataloader) * num_epochs),\n",
    "    #     num_training_steps=(len(train_dataloader) * num_epochs),\n",
    "    # )\n",
    "\n",
    "    # Instantiate dataloaders.\n",
    "    def collate_fn(examples):\n",
    "        return tokenizer.pad(\n",
    "            examples,\n",
    "            padding=\"max_length\",\n",
    "            max_length=padding_max_len,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        tokenized_train,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    eval_dataloader = DataLoader(\n",
    "        tokenized_eval,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for _, batch in enumerate(tqdm(train_dataloader)):\n",
    "            batch.to(device)\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        for _, batch in enumerate(tqdm(eval_dataloader)):\n",
    "            batch.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "            predictions = outputs.logits.argmax(dim=-1)\n",
    "            predictions, references = predictions, batch[\"labels\"]\n",
    "            metric.add_batch(\n",
    "                predictions=predictions,\n",
    "                references=references,\n",
    "            )\n",
    "\n",
    "        eval_metric = metric.compute()\n",
    "        print(f\"epoch {epoch}:\", eval_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/115 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 115/115 [01:19<00:00,  1.45it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.6862745098039216, 'f1': 0.8134110787172011}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# use all training data\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path)\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "train(model, tokenized_datasets[\"train\"], tokenized_datasets[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.20it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.6838235294117647, 'f1': 0.8122270742358079}\n",
      "budget=360\n",
      "num_rounds=10\n",
      "round=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(labeled_indices)=428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:08<00:00,  1.73it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.6838235294117647, 'f1': 0.8122270742358079}\n",
      "round=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(labeled_indices)=788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:14<00:00,  1.73it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.6985294117647058, 'f1': 0.8183161004431315}\n",
      "round=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(labeled_indices)=1148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:21<00:00,  1.70it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.6911764705882353, 'f1': 0.810810810810811}\n",
      "round=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(labeled_indices)=1508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:21<00:00,  2.25it/s]\n",
      "100%|██████████| 13/13 [00:01<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.7009803921568627, 'f1': 0.8184523809523809}\n",
      "round=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(labeled_indices)=1868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:35<00:00,  1.65it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.6936274509803921, 'f1': 0.8169838945827232}\n",
      "round=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(labeled_indices)=2228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:42<00:00,  1.63it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.678921568627451, 'f1': 0.7923930269413629}\n",
      "round=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(labeled_indices)=2588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [00:49<00:00,  1.62it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.6985294117647058, 'f1': 0.8098918083462132}\n",
      "round=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(labeled_indices)=2948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [00:56<00:00,  1.63it/s]\n",
      "100%|██████████| 13/13 [00:02<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.7009803921568627, 'f1': 0.8134556574923548}\n",
      "round=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(labeled_indices)=3308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104/104 [00:58<00:00,  1.79it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.7107843137254902, 'f1': 0.802013422818792}\n",
      "round=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(labeled_indices)=3668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [01:10<00:00,  1.62it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.6936274509803921, 'f1': 0.8085758039816232}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# random sampling\n",
    "\n",
    "import random\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path)\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "data_train = tokenized_datasets[\"train\"]\n",
    "data_eval = tokenized_datasets[\"validation\"]  # test\n",
    "\n",
    "assert len(data_train) == 3668\n",
    "candidate_indices = list(range(len(data_train)))\n",
    "\n",
    "# train an initial model using labeled data\n",
    "# TODO: always need this?\n",
    "n_start = 68\n",
    "labeled_indices = random.sample(candidate_indices, n_start)\n",
    "train(model, data_train.select(labeled_indices), data_eval)\n",
    "candidate_indices = [i for i in candidate_indices if i not in set(labeled_indices)]\n",
    "\n",
    "budget = 360\n",
    "num_rounds = len(candidate_indices) // budget\n",
    "print(f\"{budget=}\")\n",
    "print(f\"{num_rounds=}\")\n",
    "\n",
    "for round in range(num_rounds):\n",
    "    print(f\"{round=}\")\n",
    "\n",
    "    # re-init model each round\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path)\n",
    "    model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "    # choose data to label\n",
    "    chosen_indices = random.sample(candidate_indices, budget)\n",
    "\n",
    "    # obtain labels\n",
    "    labeled_indices += chosen_indices\n",
    "    print(f\"{len(labeled_indices)=}\")\n",
    "\n",
    "    # update model\n",
    "    train(model, data_train.select(labeled_indices), data_eval)\n",
    "\n",
    "    # remove labeled data from candidates\n",
    "    candidate_indices = [i for i in candidate_indices if i not in set(labeled_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.25it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.31862745098039214, 'f1': 0.0071428571428571435}\n",
      "budget=360\n",
      "num_rounds=10\n",
      "round=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X_candidates)=3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangdazhang/msr_sampling/src/active_learn/active_sampler.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  samps = torch.tensor(samps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start sampling ...\n",
      "Sampling done\n",
      "len(chosen_indices)=360\n",
      "len(labeled_indices)=428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:08<00:00,  1.72it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.6838235294117647, 'f1': 0.8122270742358079}\n",
      "round=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X_candidates)=3240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangdazhang/msr_sampling/src/active_learn/active_sampler.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  samps = torch.tensor(samps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start sampling ...\n",
      "Sampling done\n",
      "len(chosen_indices)=360\n",
      "len(labeled_indices)=788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:15<00:00,  1.66it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.6985294117647058, 'f1': 0.8110599078341014}\n",
      "round=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X_candidates)=2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangdazhang/msr_sampling/src/active_learn/active_sampler.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  samps = torch.tensor(samps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start sampling ...\n",
      "Sampling done\n",
      "len(chosen_indices)=360\n",
      "len(labeled_indices)=1148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:23<00:00,  1.55it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.6936274509803921, 'f1': 0.8091603053435115}\n",
      "round=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X_candidates)=2520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangdazhang/msr_sampling/src/active_learn/active_sampler.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  samps = torch.tensor(samps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start sampling ...\n",
      "Sampling done\n",
      "len(chosen_indices)=360\n",
      "len(labeled_indices)=1508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:30<00:00,  1.56it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.6838235294117647, 'f1': 0.8122270742358079}\n",
      "round=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X_candidates)=2160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangdazhang/msr_sampling/src/active_learn/active_sampler.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  samps = torch.tensor(samps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start sampling ...\n",
      "Sampling done\n",
      "len(chosen_indices)=360\n",
      "len(labeled_indices)=1868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:37<00:00,  1.58it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.6838235294117647, 'f1': 0.8122270742358079}\n",
      "round=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X_candidates)=1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangdazhang/msr_sampling/src/active_learn/active_sampler.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  samps = torch.tensor(samps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start sampling ...\n",
      "Sampling done\n",
      "len(chosen_indices)=360\n",
      "len(labeled_indices)=2228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:44<00:00,  1.56it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.6862745098039216, 'f1': 0.8134110787172011}\n",
      "round=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X_candidates)=1440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangdazhang/msr_sampling/src/active_learn/active_sampler.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  samps = torch.tensor(samps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start sampling ...\n",
      "Sampling done\n",
      "len(chosen_indices)=360\n",
      "len(labeled_indices)=2588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [00:52<00:00,  1.55it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.7156862745098039, 'f1': 0.8268656716417911}\n",
      "round=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X_candidates)=1080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangdazhang/msr_sampling/src/active_learn/active_sampler.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  samps = torch.tensor(samps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start sampling ...\n",
      "Sampling done\n",
      "len(chosen_indices)=360\n",
      "len(labeled_indices)=2948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [00:59<00:00,  1.56it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.7083333333333334, 'f1': 0.819423368740516}\n",
      "round=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X_candidates)=720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangdazhang/msr_sampling/src/active_learn/active_sampler.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  samps = torch.tensor(samps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start sampling ...\n",
      "Sampling done\n",
      "len(chosen_indices)=360\n",
      "len(labeled_indices)=3308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104/104 [01:06<00:00,  1.57it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.7034313725490197, 'f1': 0.7986688851913478}\n",
      "round=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X_candidates)=360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangdazhang/msr_sampling/src/active_learn/active_sampler.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  samps = torch.tensor(samps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start sampling ...\n",
      "Sampling done\n",
      "len(chosen_indices)=360\n",
      "len(labeled_indices)=3668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115/115 [01:13<00:00,  1.57it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'accuracy': 0.6838235294117647, 'f1': 0.8122270742358079}\n"
     ]
    }
   ],
   "source": [
    "# active learning\n",
    "\n",
    "import active_learn\n",
    "import random\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path)\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "data_train = tokenized_datasets[\"train\"]\n",
    "data_eval = tokenized_datasets[\"validation\"]  # test\n",
    "\n",
    "assert len(data_train) == 3668\n",
    "candidate_indices = list(range(len(data_train)))\n",
    "\n",
    "# train an initial model using labeled data\n",
    "# TODO: always need this?\n",
    "n_start = 68\n",
    "labeled_indices = random.sample(candidate_indices, n_start)\n",
    "train(model, data_train.select(labeled_indices), data_eval)\n",
    "candidate_indices = [i for i in candidate_indices if i not in set(labeled_indices)]\n",
    "\n",
    "budget = 360\n",
    "num_rounds = len(candidate_indices) // budget\n",
    "print(f\"{budget=}\")\n",
    "print(f\"{num_rounds=}\")\n",
    "\n",
    "for round in range(num_rounds):\n",
    "    print(f\"{round=}\")\n",
    "\n",
    "    # re-init model each round\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path)\n",
    "    model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "    # set up sampler\n",
    "    model = active_learn.get_active_model(model)\n",
    "    sampler = active_learn.ActiveSampler(\n",
    "        \"classification\",\n",
    "        model,\n",
    "        budget,\n",
    "        # TODO: labeled_data=X_labeled,\n",
    "    )\n",
    "\n",
    "    # TODO: add support to avoid conversion here.\n",
    "    X_candidates = []\n",
    "    for i in range(len(candidate_indices)):\n",
    "        X_candidates.append(\n",
    "            {\n",
    "                \"input_ids\": data_train[i][\"input_ids\"],\n",
    "                \"attention_mask\": data_train[i][\"attention_mask\"],\n",
    "            }\n",
    "        )\n",
    "    print(f\"{len(X_candidates)=}\")\n",
    "\n",
    "    # choose data to label\n",
    "    indices = sampler.select(X_candidates)\n",
    "    chosen_indices = [candidate_indices[i] for i in indices]\n",
    "    print(f\"{len(chosen_indices)=}\")\n",
    "\n",
    "    # obtain labels\n",
    "    labeled_indices += chosen_indices\n",
    "    print(f\"{len(labeled_indices)=}\")\n",
    "\n",
    "    # update model\n",
    "    train(model, data_train.select(labeled_indices), data_eval)\n",
    "\n",
    "    # remove labeled data from candidates\n",
    "    candidate_indices = [i for i in candidate_indices if i not in set(labeled_indices)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
