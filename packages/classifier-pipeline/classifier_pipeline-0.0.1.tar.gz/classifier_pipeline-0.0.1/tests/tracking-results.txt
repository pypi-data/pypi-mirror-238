----------Recording------------------------------------------------------------------------------------------
Recordings[932645] lepton35Missed/932645.cptv


Unmatched Tests
rodent - Opt[6s] Start-End 3 - 9, Expected[6s] 3 - 9

----------Recording------------------------------------------------------------------------------------------
Recordings[932644] lepton35Missed/932644.cptv


Unmatched Tests
mustelid - Opt[6.2s] Start-End 0.11 - 6.33, Expected[6.2s] 0.11 - 6.33

----------Recording------------------------------------------------------------------------------------------
Recordings[932592] lepton35Missed/932592.cptv


Unmatched Tests
rodent - Opt[5s] Start-End 3 - 8, Expected[5s] 3 - 8

----------Recording------------------------------------------------------------------------------------------
Recordings[932577] lepton35Missed/932577.cptv


Unmatched Tests
possum - Opt[15.0s] Start-End 4.67 - 19.67, Expected[15.0s] 4.67 - 19.67

----------Recording------------------------------------------------------------------------------------------
Recordings[932573] lepton35Missed/932573.cptv


Unmatched Tests
mustelid - Opt[1.7s] Start-End 4 - 5.67, Expected[1.1s] 4.56 - 5.67

----------Recording------------------------------------------------------------------------------------------
Recordings[932574] lepton35Missed/932574.cptv


Unmatched Tests
rat - Opt[9.9s] Start-End 3.56 - 13.44, Expected[9.9s] 3.56 - 13.44

----------Recording------------------------------------------------------------------------------------------
Recordings[932569] lepton35Missed/932569.cptv


Unmatched Tests
possum - Opt[3s] Start-End 4 - 7, Expected[3s] 4 - 7

----------Recording------------------------------------------------------------------------------------------
Recordings[932568] lepton35Missed/932568.cptv


Unmatched Tests
mustelid - Opt[1.9s] Start-End 4 - 5.89, Expected[1.3s] 4.56 - 5.89

----------Recording------------------------------------------------------------------------------------------
Recordings[932563] lepton35Missed/932563.cptv


Unmatched Tests
mustelid - Opt[1.9s] Start-End 4 - 5.89, Expected[1.3s] 4.56 - 5.89

----------Recording------------------------------------------------------------------------------------------
Recordings[932556] lepton35Missed/932556.cptv


Unmatched Tests
mustelid - Opt[6.2s] Start-End 0.11 - 6.33, Expected[6.2s] 0.11 - 6.33

Config
verbose: False

use_opt_flow: False

# Output debug information e.g. heat numbers on preview
debug: False

# root folder where the source and output folders belong
base_data_folder: "/home/gp/cacophony/classifier-data"
# Enables/Disables GPU accelerated classification
use_gpu: false

# source_folder is where the cptv files reside under. It is relative
# to base_data_folder.
source_folder: "cptv"

# tracks_folder is where the track data files will be created. It is
# specified relative to base_data_folder.
tracks_folder: "tracks"
# which folders (tags) to ignore when selecting` cptv files from source_folder
excluded_tags: ['untagged', 'dog', 'unidentified', 'hard', 'multi', 'moving','bird-kiwi', 'for_grant', 'missclassified', 'other']

# Reprocess files which have already been procestop_framessed.
reprocess: true

# Colour map override to use when exporting to MPEG. If not specified,
# a sensible default colour map is used.
# Note: This is should be a full path. It is not relative to the # base_data_folder.
# previews_colour_map: "custom_colormap.dat"

# Labels preserve this order, this means we can retrain from existing model
# add new labels to the end
labels : ['bird', 'cat', 'false-positive', 'hedgehog', 'insect', 'leporidae', 'mustelid', 'possum', 'rodent', 'wallaby']

# Number of worker threads to use.  0 disables worker pool and forces a single thread.
worker_threads: 1

tracking:
    #
    #  Tracking algorithm
    #

    # Default algorithm used to calculate the image background.   Must be "preview" or "stats"
    # Preview uses the preview time in the video (if it exists in the meta for cptv file)
    # Stats uses a statistical analysis of the whole video to get background levels
    background_calc: preview
    preview_ignore_frames: 2

    # these parameters are associated with the preview background method
    preview:
        # Temp_thresh is calculated based on the preview min, max and mean, and temp_thresh value
        dynamic_thresh: True

        # When calculating the background ignore the last frames of the preview as the motion detection
        # will still be triggering during this time.
        ignore_frames: 2

        # Minimum raw (temperature) value to be tracked
        temp_thresh: 2900

        # Minimum raw temperature difference between background and track
        background_thresh: 10

        # Minimum raw temperature difference between background and track
        delta_thresh: 20

    motion:
        #if set to True Temp_thresh is calculated based on the minimum background temperature
        #of the preview, or whole clip depending on cptv type
        dynamic_thresh: True
        camera_thresholds:
            lepton3:
              camera_model: "lepton3"
              # Default temperature threshold require for tracking
              temp_thresh: 2900
              # Minimum raw temperature difference between background and track
              background_thresh: 20
              # Min/Max temperature threshold value to use if dynamic threshold is true
              max_temp_thresh: null
              min_temp_thresh: null
              default: True
          # discard tracks that do not have enough delta within the window (i.e. pixels that change a lot)
              track_min_delta: 1.0
              track_max_delta: 150
            lepton35:
                camera_model: "lepton3.5"
                temp_thresh: 28000
                background_thresh: 50 # 1 degrees
                max_temp_thresh: null
                min_temp_thresh: null
                # discard tracks that do not have enough delta within the window (i.e. pixels that change a lot)
                # tracks that move slowly have low deltas...
                track_min_delta: 1.0
                track_max_delta: 150

    # these parameters are associ/home/gp/cacophony/classifier-data/classify/possum35.mp4ated with the stats background method
    stats:
        # auto threshold needs to find a near maximum value to calculate the threshold level
        # a better solution might be the mean of the max of each frame?
        threshold_percentile: 99.9

        # minimum allowed threshold for number of pixels changed from average background, smaller values detect more objects, but bring up additional false positives
        min_threshold: 30

        # minimum allowed threshold for number of pixels changed from average background, smaller values detect more objects, but bring up additional false positives
        max_threshold: 50


    # any clips with a mean temperature hotter than this will be excluded
    max_mean_temperature_threshold: 10000

    # any clips with a temperature dynamic range greater than this will be excluded
    max_temperature_range_threshold: 10000

    # measures how different pixels are from estimated background, if they are on average less different than this then
    # video is considered to be static.
    static_background_threshold: 4.0

    # number of pixels round the edge to ignore due to strange values
    edge_pixels: 1

    # number of pixels around object to pad.
    # Note: frame_padding must be at least 3 or some frames may be too small for classification and program may crash
    frame_padding: 4

    # dilation pixels:  This is the number of pixels to grow the mask of interesting bits.
    # The higher the value, the further apart things (bits of animal, or animals) will be linked together as one object
    dilation_pixels: 2

    # wait this many frames for animal to "reappear" after it is last detected.
    remove_track_after_frames: 18

    # when enabled smooths tracks so that track dimensions do not change too quickly.
    track_smoothing: False

    high_quality_optical_flow: False

    # how much to threshold thermal before calculating optical flow.
    flow_threshold: 40

    # maximum number of tracks to extract from a clip.  Takes the n best tracks.
    max_tracks: 10

    areas_of_interest:
        # minimum pixels of interest each area of interest should have.
        min_mass: 9.0

        # minimum variation of pixels between then frame and previous for each area of interest.
        pixel_variance: 2.0

        # strategy to use when dealing with regions of interest that are cropped against the side of the frame
        # in general these regions often do not have enough information to accurately identify the animal.
        # options are
        # 'all': All cropped regions are included, good for classifier
        # 'cautious': Regions that are only cropped a bit are let through, this is good for training data
        # 'none': No cropped regions are permitted.  This is the most safe.
        cropped_regions_strategy: "cautious"

    filters:
        # regions with a movement less than this have their tracking scored based of x,y matching, instead of than mid points
        moving_vel_thresh: 4

        # discard any tracks that overlap with other tracks more than this.   T than this length in seconds
        track_overlap_ratio: 0.5

        # discard any tracks shorter than this length in seconds
        min_duration_secs: 1.0

        # dicard any tracks that do not move enough, (move less than this)
        track_min_offset: 4.0

        # discard tracks that do not have enough delta within the window (i.e. pixels that change a lot)
        track_min_delta: 1.0

        # discard tracks that do not have enough enough average mass.
        track_min_mass: 2.0

    # Add verbose logging about tracks generated
    verbose: False
    # Minimum confidence of track tag to accept
    min_tag_confidence: 0.6
load:
    high_quality_optical_flow: False
    # precidence of tags (lower first)
    tag_precedence:
        0: ["wallaby","bird", "false-positive", "hedgehog", "possum", "rodent", "mustelid", "cat", "kiwi", "dog", "leporidae", "human", "insect", "pest"]
        1: ["unidentified", "other"]
        2: ["part","bad track"]

    # Use fast BLOSC compression (requires plugin), when saving tracks to database
    enable_compression: False

    # Includes the filtered channel in tracks database.  This is typically not used.  If compression is enabled the
    # filesize can be reduced by not including it.
    include_filtered_channel: True

    # Create a MP4 preview of the recording.  Options are "none", "raw", "boxes", "classified", "tracking"
    # none - won't create a preview video
    # raw - just the video (no classification or tracks)
    # boxes - show track boxes but no text
    # classified - show tracks and classification values
    # tracking -  four frame video view, including thermal, filtered, mask and flow layers
    preview: null

    #cache buffer frame to disk reducing memory usage
    cache_to_disk: False
train:
    # model_resnet, model_lq, or model_hq
    model: "keras"

    hyper_params:
        # training
        # retrain layers x and above
        # just conv5 on resnet
        #base_training: True
        train_process_threads: 1
        # retrain_layer: 249
        buffer_size: 100
        use_segments: True
        dropout: 0.3
        model_name: "inceptionv3"
        lstm: False
        shuffle: True
        train_load_threads: 1
        maximum_train_preload: 700
        ue_thermal: True
        use_filtered: False
        batch_size: 8
        learning_rate: 0.001
        learning_rate_decay: 1.0
        l2_reg: 0
        label_smoothing: 0.1
        keep_prob: 0.2
        # model
        batch_norm: true
        lstm_units: 25
        gru_units: 512
        enable_flow: true
        # augmentation
        augmentation: true
        thermal_threshold: 10
        scale_frequency: 0.5
        segment_type: ALL_RANDOM
        type: 1
        square_width: 5
        dense_sizes: []
        frame_size: 32
        keep_edge: true
        #  resnet
    resnet_params:
        num_filters: 32
        kernel_size: 3
        conv_stride: 2
        # block sizes can be left null and will be calculated based of resnet_size
        block_sizes : [3, 4, 6, 3]
        block_strides: [1, 2, 2, 2]
        bottleneck: false
        resnet_size: 50
    # Number of epochs to train for
    epochs: 300
      # use a gru cell or a lstm cell
    use_gru: false

    # Location to write various training outputs to. Relative to
    # base_data_folder. Defaults to "training"
    # train_dir: "training"

classify_tracking:
    # Note: frame_padding must be at least 3 or some frames may be too small for classification
    frame_padding: 4
    high_quality_optical_flow: False
    filters:
        track_overlap_ratio: 0.5
        min_duration_secs: 1.0
        track_min_offset: 4.0
        track_min_delta: 1.0
        track_min_mass: 2.0

classify:
    # Writes metadata to standard out instead of a file with extension .txt
    meta_to_stdout : False
 #    model: "/home/gp/newmodel0309/training-best.sav"
    models:
      - name: "Inc3"
        id: 2
        model_file: "/home/gp/cacophony/classifier-data/allModel/inc3/keepEdge/inc3KeepEdge_TEST/saved_model.pb"
        model_weights: "/home/gp/cacophony/classifier-data/allModel/inc3/keepEdge/inc3KeepEdge_TEST/val_acc"

      #
      - name: "wall not"
        id: 1
        model_file: "/home/gp/cacophony/classifier-data/wallabyModel/inc3WallNot/saved_model.pb"
        wallaby: True
        tag_scores:
            wallaby: 1
        # /home/gp/cacophony/classifier-data/allModel/dennisModelAgain/resnet18/saved_model.pb"
            # - name: "WallabY FRame"
          #   id: 1
          #   model_file: "/home/gp/cacophony/classifier-data/allModel/resnetFrame/wallabyFrame/saved_model.pb"
          #   tag_scores:
          #       bird: 4
          #       default: 1
          # - name: "INC2"
          #   id: 2
          #   # model_file: "/home/gp/cacophony/classifier-data/allModel/inc2Filtered/saved_model.pb"
          #   model_file: "/home/gp/cacophony/classifier-data/allModel/inc2Filtered/wallabyNot/saved_model.pb"
          #   # model_file: "/home/gp/cacophony/classifier-data/allModel/inc3/allBack/val_acc/saved_model.pb"
          #   default: 2
          #   ignored_tags: ["mustelid"]
    # model: "/home/gp/cacophony/classifier-data/allModel/inc3/allBack/val_acc/saved_model.pb"
    # model: "/home/gp/cacophony/classifier-data/allModel/inc3/val_acc/saved_model.pb"

    model: "/home/gp/cacophony/classifier-data/allModel/inc3/keepEdge/inc3KeepEdge_TEST/tflite/converted_model.tflite"
    # model: "/home/gp/cacophony/classifier-data/allModel/inc3/neuralModel/saved_model.xml"
    # Path to pretrained Model use for classification (This should be the base filename without any extension)
    # model: "/home/gp/cacophony/classifier-data/wallabyModel/walLargeFineEsp_TEST/saved_model.pb"
    # model: "/home/gp/cacophony/classifier-data/models/resnet_wallaby_allframes"
    # model: "/home/gp/cacophony/classifier-data/movement/wallabymoveType5"
    # model: "/home/gp/cacophony/classifiesr-data/important_frames/wallaby/lstm"
    # model: "/home/gp/cacophony/classifier-data/important_frames/models/res_select_0001/"
    # Create a MP4 preview after classification of recording.  Options are "none", "raw", "classified", "tracking"
    # See extract:preview for details on each option.
    preview: "tracking"

    # folder is where classifier output and mp4s will be created.  It is specified relative to the base_data_folder
    classify_folder: "classify"

    #cache buffer frame to disk reducing memory usage
    cache_to_disk: False
evaluate:
    # Evalulates results against pre-tagged ground truth.
    show_extended_evaluation: False

    # number of seconds between clips required to trigger a a new visit
    new_visit_threshold: 180

    # false positive's and 'none' can be mapped to the same label as they represent the same idea.
    null_tags: ["false-positive", "none", "no-tag"]

build:
    test_clips_folder: "testset"
    # uses split from previous run
    use_previous_split: False

    # file to load previous split from
    previous_split: template.dat

    # labels to ignore
    ignore_labels: ["false-positive"]

    # if true removes any trapped animal footage from dataset.
    # trapped footage can be a problem as there tends to be lots of it and the animals do not move in a normal way.
    # however, bin weighting will generally take care of the excessive footage problem.
    excluded_trap: True

    # sets a maximum number of segments per bin, where the cap is this many standard deviations above the norm.
    # bins with more than this number of segments will be weighted lower so that their segments are not lost, but
    # will be sampled less frequently.
    cap_bin_weight: 1.5

    # adjusts the weight for each animal class.  Setting this lower for animals that are less represented can help
    # with training, otherwise the few examples we have will be used excessively.  This also helps build a prior for
    # the class suggesting that the class is more or less likely.  For example bumping up the human weighting will cause
    # the classifier lean towards guessing human when it is not sure.

    # xxx this doesn't actually work, and should be removed.
    label_weights: {"bird-kiwi": 0.1}

    # clips after this date will be ignored.
    # note: this is based on the UTC date.

    # minimum average mass for test segment
    test_min_mass: 30

    train_min_mass: 16

    # any day with a track this number of second or longer will be excluded from the validation set.
    # this is because it would be more useful to train on the long track, and we don't want the track to dominate the
    # validation set (otherwise a single track could end up being 50% of the data)
    max_validation_set_track_duration: 120

    # number of segments to include in test set for each class (multiplied by label weights)
    test_set_count: 300

    # minimum number of bins used for test set
    test_set_bins: 10

    # number of seconds each segment should be
    segment_length: 25

    # number of seconds segments are spaced apart
    segment_spacing: 1

    # when building a dataset we want to use many different tracks if aren't building a big dataset
    max_segments_per_track: 2
